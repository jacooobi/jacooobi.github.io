<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0"><channel><title>ML Odyssey</title><description>Blog about machine learning, statistics and other Computer Science related stuff. I write about things I've learned while taking online courses.</description><link>http://localhost:2368/</link><generator>Ghost 0.7</generator><lastBuildDate>Sun, 19 Jun 2016 17:40:20 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title>Neural networks - a nervous shock</title><description>&lt;p&gt;Until some time ago, there was a list of programming and computer science related terms that used to blow my mind. I'd think of metaprogramming or functional programming concepts like immutability and monads and assume that they are massively complex mechanisms involved under the hood. Because these are quite odd&lt;/p&gt;</description><link>http://localhost:2368/neural-networks/</link><guid isPermaLink="false">7b3aac18-f199-4e73-b681-a2694a5197f8</guid><dc:creator>Jacek Kubiak</dc:creator><pubDate>Fri, 08 Apr 2016 22:16:56 GMT</pubDate><media:content url="http://localhost:2368/content/images/2016/06/network.jpg" medium="image"/><content:encoded>&lt;img src="http://localhost:2368/content/images/2016/06/network.jpg" alt="Neural networks - a nervous shock"&gt;&lt;p&gt;Until some time ago, there was a list of programming and computer science related terms that used to blow my mind. I'd think of metaprogramming or functional programming concepts like immutability and monads and assume that they are massively complex mechanisms involved under the hood. Because these are quite odd sounding words you tend to give them more respect and sort of surround them with a mysterious vibe. If you share the same point of view and occasionally learn new things, you may often feel dissapointed afterwards. "Is that it?" - you may think. Computer science is both very complex and simple. And on top of it, it's extremely difficult to create simple things in programming. Needless to say, when I first heard about neural networks I started imagining this abstruse design that's supposed to mimic brain functions and was hoping for more than ever.&lt;/p&gt;

&lt;p&gt;So as you probably now know, instead of a mind bending solution, I was presented with a simple but robust and well-thought design. Neural networks is an old concept, the first computational model was introduced in 1943 and was a topic of research since then. What is interesting, is that it never really took off until recently when deep learning - neural network with subnetworks in the hidden layers - was invented. The are two reasons why NN were not as popular. First of all, to produce significant results, you need a lot of computational power and even though the CPUs get exponentially faster every few years, the main power boost was provided by the recent growth of GPUs which currently totally outperform CPUs. The second reason is that NN are hard to train, it takes a lot of time to apply proper weights and many times we get little to no feedback whether we are going in a good direction (when choosing network structure or tweaking the number of layers).&lt;/p&gt;

&lt;p&gt;Yes, I'm aware I didn't explain the terms above. Let's start from the very beginning. This is a very simple neural network.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/06/IMAG0489-3.jpg" alt="Neural networks - a nervous shock"&gt;&lt;/p&gt;

&lt;p&gt;What you see is a perceptron which has two inputs and produces a single output. Inputs are binary, so you can give either zero or one. On each edge, there is a weight, value which gets multiplied by our input. Finally, the perceptron holds a threshold, a number which determines the output. We take the sum of inputs multiplied by weights and compare this sum with the threshold and if it is greater then the perceptron returns 1, if less or equal we get 0. We can model a simple logic OR function using a single perceptron and two inputs, just like you can see on the picture below.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/06/IMAG0490-4.jpg" alt="Neural networks - a nervous shock"&gt;&lt;/p&gt;

&lt;p&gt;Now that's cool but useless. The same thing we could do using logistic regression. What neural networks really excel at, are (mostly) classification problems with large number of variables. Logistic regression started to actually struggle when we introduced multiple variables. It still works, but it takes massive amount of time for gradient descent to come up with a proper polynomial parameters to fit the training data. In a common programming problem, that is image recognition, we use each pixel of an image as input. Given a small image, consisting of just 50x50 pixels, each in rgb(three values instead of one, like in greyscale, ranging from 0 to 255) we will end up with 7500 variables. A neural network will have no problem coping with this.&lt;/p&gt;

&lt;p&gt;Nowadays, we use sigmoid neurons rather than perceptrons. What is the difference? They look the same, but with sigmoid neurons we can work using a different input than binary, that is any value between 0 and 1. There is also a bias value, which is almost the same as threshold, but it has an opposite sign. So we actually end up summing all the weights multiplied by inputs and finally, add the bias. This total value is passed as an argument to the sigmoid function, which is our neuron output and returns a values ranging from 0 to 1. I've talked about sigmoid functions a bit more in the previous post.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/06/sigmoid.png" alt="Neural networks - a nervous shock"&gt;&lt;/p&gt;

&lt;p&gt;Neural networks have layers. The network used to compute an OR function had just two layers. Input and output. If we were to introduce another layer, computes a some sort of intermediate result, we would add it in between input and output. This type of layers are called hidden layers. Without them, it would be impossible to use NN for anything more complicated than simple linear functions. This is where the real power of networks resides. In Deep Learning, we go even further. Within the hidden layers, there are other independant neural networks which sometimes have other networks nested inside. This technique was used in Alpha Go, the famous computer who beat Lee Sedol, one of the best players of the decade, in the game called Go.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/06/networks.png" alt="Neural networks - a nervous shock"&gt;&lt;/p&gt;

&lt;p&gt;I casually mentioned image recognition as one of the prominent fields where Neural Networks are applied. In fact, NN are everywhere. Character recognition, stock market prediction, robotics, you name it. They can also be a building block in reinforcement learning, a third type of machine learning, after supervised and unsupervised learning.&lt;/p&gt;

&lt;p&gt;Reinforcement learning differs from supervised learning as there aren't any sets of correct input-output pairs provided. Instead, it is concentrated on a constant reevaluation of an environment, where each decision results in a reward if it was good and a penalty - in case it was incorrect. This is like training a dog to play fetch, if it chases the ball and returns it, you might give it a snack. It's worth noting that in reinforcement learning we aren't necessarily going to finish executing the program, it is supposed to run looped and go through a constant action-feedback-(reward|penalty) cycle. This type of learning is a type of problem, where an agent has to find the best possible action in his current state.&lt;/p&gt;

&lt;p&gt;Areas where RL can be applied are wide but I wanted to show you something really cool. Turns out Google's research team DeepMind developed an &lt;a href="http://www.wired.co.uk/article/google-deepmind-atari"&gt;algorithm&lt;/a&gt; which   taught itself to play almost 50 video games including Space Invaders and Pong. There is also a guy, who used RL to play &lt;a href="http://sarvagyavaish.github.io/FlappyBirdRL/"&gt;Flappy Bird&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Neural networks, thanks to deep learning, are gaining more exposure nowadays. They offer an easy way to start playing with machine learning. Even though they are a simple concept, with a proper structure and adjusted weights, you might be able to produce suprisingly good results like an algorithm which given an image is able to tell what number the image shows, with over 95% accuracy! (More on that in the Michael Nielsen's free &lt;a href="http://neuralnetworksanddeeplearning.com/chap1.html"&gt;book&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Oh and one more thing, since I don't post often, you might be interested a &lt;a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg"&gt;great video series&lt;/a&gt; which presents different machine learning papers in a very accessible way, all that in under 2 minutes!&lt;/p&gt;</content:encoded></item><item><title>On supervised and unsupervised learning. Gradient descent demystified.</title><description>&lt;p&gt;Machine learning is a broad field with plenty of applications. In order to get a better overview of them, let's assume that there are two types of problems - solved either with supervised or unsupervised learning. That said, please note this is just one of the several possible ways to&lt;/p&gt;</description><link>http://localhost:2368/supervised-and-unsupervised/</link><guid isPermaLink="false">d3a35f24-5691-4a3d-966c-f911f0394149</guid><dc:creator>Jacek Kubiak</dc:creator><pubDate>Thu, 07 Apr 2016 19:59:00 GMT</pubDate><content:encoded>&lt;p&gt;Machine learning is a broad field with plenty of applications. In order to get a better overview of them, let's assume that there are two types of problems - solved either with supervised or unsupervised learning. That said, please note this is just one of the several possible ways to categorise ML tasks. &lt;/p&gt;

&lt;p&gt;So what are the main differences between these two? In supervised learning, an algorithm is being fed an already labelled data (pairs called input and output also known as training data). Its job is to come up with a formula or simply 'learn' the rules that map inputs to output. A good example would be an algorithm which can predict whether a tumor is malignant or benign based on e.g. tumor size. &lt;/p&gt;

&lt;p&gt;On the other hand, in unsupervised learning the training step is omitted, there isn't any labelled data but instead an algorithm's task is to find the structure in the input data. For instance, let's say we are selling whisky and we've gathered a spreadsheet containing all the purchases made by our clients. We would like to mail them a newsletter including the info about our currently discounted alcohol beverages. We run promotions often and don't want to spam our customers, so we will use the power of unsupervised learning. How? By clustering the clients into groups which are more or less interested in certain types of whisky. This way, only those more likely to care, are going to receive an email. &lt;/p&gt;

&lt;p&gt;Unsupervised learning deserves its own post, so worry not, clusters, centroids and more importantly - becoming a marketing ninja will be covered soon. For now, let's dive a little deeper into supervised learning and its two main categories: regression and classification.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Regression is a term coined by biologist, who discovered that the heights of descendants of tall ancestors tend to regress down towards a normal average. Cool huh? Anyway, the regression analysis is widely used in statistics and we will benefit from it too. Imagine we work as a junior real estate agent. Sometimes our job is to estimate the price of a house. We don't have much knowledge about housing prices yet but luckily we hold documents with training data. They include houses' area and a price and it should be enough to find a formula that will allow us estimate a price of any house.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/04/hLhYS5J---Imgur-1.png" alt=""&gt;
&lt;center&gt; &lt;br&gt;
&lt;em&gt;The line is our hypothesis function whereas crosses denote single training data examples&lt;/em&gt;
&lt;/center&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;We are now going to use linear regression to predict a single output value. The notion that we guess the price for a new house, one we don't have data about, is resolved around the hypothesis function. In our case, this is a straight line which tries to fit (cross, touch) as many training examples as possible. Its formula is the same as the formula for a linear function, but with slightly different notation.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;$h_\theta(x) = \theta_0 + \theta_1 x$ &lt;br&gt; &lt;br&gt;
$\theta_0 , \theta_1 \hbox{ - adjustable params}$
&lt;/center&gt; &lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;The parameters determine the shape of the function. Our job is to make sure they are correct, less accurate values will result in false output prediction. Since there are no constraints on the parameters, we could pick a few starting values and using trial and error determine whether they are correct. In simpler scenarios, we can always take a glance at a chart. This technique is not foolproof but luckily there is a better option - use cost function.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;$J(\theta_0, \theta_1) = \dfrac {1}{2m} \displaystyle \sum_{i=1}^m \left (h_\theta (x^{(i)}) - y^{(i)} \right)^2$ &lt;br&gt;
&lt;/center&gt; &lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Without going into details, this function takes theta parameters and returns a value. The lower this value is, the better params we selected. We also want to avoid a situation when the hypothesis function is underfitted, which means that it aligns with several training examples only. Our final ingredient is going to be gradient descent. This algorithm has one job, to find the suitable theta parameters.&lt;/p&gt;

&lt;p&gt;While there's an extensive article about gradient descent on &lt;a href="https://www.wikiwand.com/en/Gradient_descent"&gt;wikipedia&lt;/a&gt; I will try to be as brief as I can get. Gradient descent is a general optimization algorithm used for finding local maximum or minimum values. You might be familiar with e.g. hill-climbing algorithm or overall, greedy algorithms. These algorithms  are known for always choosing the best possible step whereas sometimes the slighly worse solution in few steps earlier, could lead to a totally different, much better final result. Gradient descent uses the same approach, either make sure that there is only one local minimum or seed it with the correct starting values.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/04/gradient-descent.png" alt=""&gt;
&lt;center&gt;&lt;em&gt;Gradient descent algorithm - depending on a starting point, a different local optimum is found&lt;/em&gt;&lt;/center&gt; &lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;The cost function combined with the gradient descent is a duo that delivers. If everything went fine, we got a proper pair of theta0, theta1 values and the hypothesis function can be used to predict house prices with very solid confidence.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Whereas linear regression focuses on producing a continuous output, classification is about discrete values representing different groups. Choosing which tumors are more likely to be malignant or benign is nothing else but a classification task. It assigns cases to one of two groups 0 - bening and 1 - malignant. A simple chart with a training data drawn would look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/04/bHxHsnS---Imgur.jpg" alt=""&gt;&lt;/p&gt;

&lt;p&gt;Logistic regressions (yeah, regression algorithm for classification task - that's confusing) is a go-to method for such cases. If you were reading carefully, you now know that when it comes to linear regression, we need a hypothesis and a cost functions, with parameters for the latter calculated by gradient descent. Logistic regression is the same, just the formulas for the functions are slightly modified.&lt;/p&gt;

&lt;p&gt;We are going to assign labels 0(benign) or 1(malignant) to patients' cases so it would be optimal if the hypothesis function returned values between 0 and 1. A linear function can't do that so allow me to introduce the sigmoid function!&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/04/Logistic-curve-svg.png" alt=""&gt;
&lt;center&gt;&lt;em&gt;The sigmoid function&lt;/em&gt;&lt;/center&gt; &lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;This function asymptotes at 0 and 1 and has everything we need. If the result is let's say 0.3, it means that it has 30% chance of belonging in the group 1 and 70% chance of being in the group 0. As a result, it gets labelled as benign tumor.&lt;/p&gt;

&lt;p&gt;The cost function is also going to need a slight tweaking. Combined with the gradient descent, we will should be able to find nice parameters that will allow for sigmoid function to fit the data well. &lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Both linear and logistic regression are standard tools in the world of supervised learning. The examples in this post used only one variable for calculating the hypothesis function but we can easily use more. However finding proper theta parameters will not be as easy. It often is a mundane process, but when we finally run an algorithm and it works, the satisfaction is definitely there.&lt;/p&gt;

&lt;p&gt;Sources: &lt;br&gt;
[1] Wikipedia
[2] Coursera&lt;/p&gt;</content:encoded></item><item><title>Getting started</title><description>&lt;p&gt;Since you've already made your way here, there is a good chance you are one of those who find artificial intelligence fascinating. I do too, hence the blog. For quite some time now, I've been closely following the news and reading up on this topic. There is no doubt that&lt;/p&gt;</description><link>http://localhost:2368/getting-started/</link><guid isPermaLink="false">30c44566-fb14-4abb-ad30-7f8fd5b07b24</guid><dc:creator>Jacek Kubiak</dc:creator><pubDate>Mon, 28 Mar 2016 16:27:21 GMT</pubDate><media:content url="http://localhost:2368/content/images/2016/03/machina.png" medium="image"/><content:encoded>&lt;img src="http://localhost:2368/content/images/2016/03/machina.png" alt="Getting started"&gt;&lt;p&gt;Since you've already made your way here, there is a good chance you are one of those who find artificial intelligence fascinating. I do too, hence the blog. For quite some time now, I've been closely following the news and reading up on this topic. There is no doubt that we are witnessing a giant progress in AI and before we realise, computers will &lt;del&gt;take over the world&lt;/del&gt; fill in the job positions that require people to perform mundane tasks and assist us in our day to day activities. &lt;/p&gt;

&lt;p&gt;I'm not going to blog about how the world is going to change but instead you will here find my notes in a form of blogposts. What notes? Ah, right I forgot to tell you! I've recently enrolled to machine learning class on &lt;a href="https://www.coursera.org"&gt;Coursera&lt;/a&gt;, plus I started working through the &lt;a href="https://www.openintro.org/stat/"&gt;Open Intro Statistics textbook&lt;/a&gt;. The notes will contain the material from the sources above. Hopefully, writing them will help me get familiar with the new terms and the readers will find them worthy as well.&lt;/p&gt;

&lt;p&gt;This machine learning thing... I did hear this term somewhere, but do you mind telling me what's all the fuss about? Sure thing! Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed. It allows us to model and develop software which otherwise would be nearly impossible to create because of the endless amount of conditions and factors that change the program's behaviour. Think of a 'simple program' that given an image would tell you whether it shows a bird or a park &lt;a href="http://xkcd.com/1425/"&gt;obligatory xkcd comic&lt;/a&gt;. Flickr actually created this app and you can check it &lt;a href="http://parkorbird.flickr.com/"&gt;here&lt;/a&gt;. All they had to do was feed the algorithm some training data explicitly labeled as a park or a bird and the program took over from there. This was an example of a supervised learning. Supervised and unsupervised learning are the two main types of ML algorithms. I'm going to talk more about them in the next post.&lt;/p&gt;

&lt;p&gt;The bird-or-park program is cool but it's use case is rather limited. Is machine learning a real thing? Why would we be convinced that it's going to have a meaningful impact on us in the near future? Oh well, for a number of reasons actually.&lt;/p&gt;

&lt;h2 id="chessandgocomputersdontstandachanceordothey"&gt;Chess and go? Computers don't stand a chance... or do they?&lt;/h2&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/chess.png" alt="Getting started"&gt;&lt;/p&gt;

&lt;p&gt;For quite some time, people were assured that computers will never achieve the same level of intelligence as humans. In order to measure computer mental abilities, we had them play board games, such as chess or go, versus humans. Because these games have a large problem space, that is a total number of possible moves (10&lt;sup&gt;50&lt;/sup&gt;, 10&lt;sup&gt;170&lt;/sup&gt; for chess and go respectively) it is impossible for a computer to use the brute force method and come up with a solution in a feasible amount of time.&lt;/p&gt;

&lt;p&gt;For chess, this thinking turned out to be wrong. The IBM's Deep Blue was a chess playing computer, capable of evaluating 200 million positions per second. In May 1997 Deep Blue defeated Garry Kasparov, who at that time was a world champion. The result was 4-2 in favour of Deep Blue and despite &lt;a href="http://www.wired.com/2012/09/deep-blue-computer-bug/"&gt;controversies&lt;/a&gt; the computer was declared the winner.&lt;/p&gt;

&lt;p&gt;When it comes to go, the same approach is not going to work for many upcoming years even though the computing power is rising exponentially. Go is simply much more complex than chess. This didn't discourage the Google's Deep Mind team who created Alpha Go. AlphaGo's algorithm uses a Monte Carlo tree search to find its moves based on knowledge previously "learned" by machine learning, specifically by an artificial neural network (a deep learning kind) by extensive training, both from human and computer play. We could say that through that training, AlphaGo obtained a form of human intuition which allows it to sort of "see" the areas on the board where the best moves could take place. This was a massive improvement from the brute force method used by Deep Blue. In March 2016 we witnessed history being made as Alpha Go defeated 4-1 Lee Sidol, South Korean professional considered as one of the greatest Go players.&lt;/p&gt;

&lt;p&gt;Alpha Go's victory was something more than another proof that machine always eventually becomes better than a human at performing particular task. It proved that the deep learning method which uses neural networks, modelled after the brain’s neurons is a viable method, even though that in the 1980s it was dismissed as bunk by the AI establishment.&lt;/p&gt;

&lt;h2 id="fromsmalltobigdata"&gt;From small to big data&lt;/h2&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2016/03/memor.png" alt="Getting started"&gt;
The Apollo Guidance Computer used in the Apollo 11 mission  (&lt;a href="https://www.flickr.com/photos/projectapolloarchive/albums"&gt;btw I totally recommend checking the photographs taken by the crew during the expedition&lt;/a&gt;) had 74 kilobytes of memory. This is several orders of magnitude less than what we have in ... our personal computers. External storage devices have more capacity as well and even if you run out of space there are still cloud services offering you pretty much an unlimited space. As a result, we are not only storing but also generating more data than never before. It's hard to comprehend but it turns out we have produced more pieces of information in the last two years than ever since we gathered the data.&lt;/p&gt;

&lt;p&gt;Machine learning won't work if we don't provide solid training examples. More data naturally means more capabilities. With the rise of wearables, we've started tracking our heart rate, blood pressure, sleep patterns and nowadays we are able to quickly discover that a certain person has e.g. heart arrhythmia. All this person has to do is wear a watch long enough to produce relevant pieces of information and the ML algorithm built into the watch is able to detect any potential symptoms based on thousands of other training examples.&lt;/p&gt;

&lt;h2 id="machinelearningisgoingmainstream"&gt;Machine learning is going mainstream&lt;/h2&gt;

&lt;p&gt;The example given above is just a tip of the iceberg. Machine learning, even though rather unnoticeable by the less tech savvy people, is everywhere. Thanks to spam filters we are no longer concerned with ads and malicious emails. Think of all the recommendations we get while watching youtube videos, listening to music on spotify or shopping on amazon. Google search is personalised based on your browser history. Both speech and image recognition have greatly improved over the past few years. We now have a personal assistants like Siri - that's a great use of natural language processing. Who knew? All these examples have something in common and suprise suprise... it's machine learning. &lt;/p&gt;

&lt;p&gt;Wow, that's quite a list. We can be certain that it will only keep growing, as we produce more and more data allowing us to apply ML algorithms to new areas. Looks like there is no coming back ;)&lt;/p&gt;

&lt;h2 id="excitingnews"&gt;Exciting news&lt;/h2&gt;

&lt;p&gt;As I said at the beginning, for the next few months I will be posting notes about topics related to machine learning and statistics. If you found yourself curious feel more than free to stop by from time to time as I publish new content. In the meantime check out the curated list of resources I've prepared for you.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471"&gt;https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471&lt;/a&gt; - good and short introduction to machine learning&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wired.com/2014/10/future-of-artificial-intelligence/"&gt;http://www.wired.com/2014/10/future-of-artificial-intelligence/&lt;/a&gt; - an article discussing the key factors which contributed to ML's recent growth.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide/"&gt;http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide/&lt;/a&gt; - long and not so easy (but rewarding!) series of posts that serve as a very thorough intro.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/wiki/index"&gt;https://www.reddit.com/r/MachineLearning/wiki/index&lt;/a&gt; - subreddit dedicated to... you guessed it - machine learning. There's a lot of interesting stuff there poping out every day.&lt;/li&gt;
&lt;li&gt;and of course, if you'd also like to take a Coursera class you can find it &lt;a href="https://www.coursera.org/learn/machine-learning"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item></channel></rss>